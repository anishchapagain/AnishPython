{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "237b919f04ea2f36",
      "metadata": {
        "id": "237b919f04ea2f36"
      },
      "source": [
        "## Using and comparing **spaCy** for <b><i>POS, Lemma, and NER with NLTK - stemming</i></b>"
      ]
    },
    {
      "cell_type": "code",
      "id": "1ab74a320a96b706",
      "metadata": {
        "id": "1ab74a320a96b706"
      },
      "source": [
        "# !pip install spacy --upgrade"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T04:31:32.728373Z",
          "start_time": "2024-10-17T04:31:17.347936Z"
        },
        "id": "ea212629e73d4cb2",
        "outputId": "d907094b-594d-46d5-901c-59da4d04b01a"
      },
      "cell_type": "code",
      "source": [
        "# !python -m spacy download en_core_web_sm"
      ],
      "id": "ea212629e73d4cb2",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.8/12.8 MB 6.7 MB/s eta 0:00:02\n",
            "     ---- ----------------------------------- 1.6/12.8 MB 6.5 MB/s eta 0:00:02\n",
            "     ------- -------------------------------- 2.4/12.8 MB 4.5 MB/s eta 0:00:03\n",
            "     --------- ------------------------------ 2.9/12.8 MB 3.7 MB/s eta 0:00:03\n",
            "     --------- ------------------------------ 3.1/12.8 MB 3.5 MB/s eta 0:00:03\n",
            "     ----------- ---------------------------- 3.7/12.8 MB 3.0 MB/s eta 0:00:04\n",
            "     ------------ --------------------------- 3.9/12.8 MB 2.8 MB/s eta 0:00:04\n",
            "     ------------ --------------------------- 3.9/12.8 MB 2.8 MB/s eta 0:00:04\n",
            "     ------------- -------------------------- 4.2/12.8 MB 2.3 MB/s eta 0:00:04\n",
            "     ------------- -------------------------- 4.5/12.8 MB 2.2 MB/s eta 0:00:04\n",
            "     ------------- -------------------------- 4.5/12.8 MB 2.2 MB/s eta 0:00:04\n",
            "     ------------- -------------------------- 4.5/12.8 MB 2.2 MB/s eta 0:00:04\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     -------------- ------------------------- 4.7/12.8 MB 1.7 MB/s eta 0:00:05\n",
            "     --------------- ------------------------ 5.0/12.8 MB 1.0 MB/s eta 0:00:08\n",
            "     --------------- ------------------------ 5.0/12.8 MB 1.0 MB/s eta 0:00:08\n",
            "     --------------- ----------------------- 5.2/12.8 MB 971.9 kB/s eta 0:00:08\n",
            "     --------------- ----------------------- 5.2/12.8 MB 971.9 kB/s eta 0:00:08\n",
            "     ---------------- ---------------------- 5.5/12.8 MB 961.5 kB/s eta 0:00:08\n",
            "     ----------------- --------------------- 5.8/12.8 MB 967.8 kB/s eta 0:00:08\n",
            "     ------------------ -------------------- 6.0/12.8 MB 979.0 kB/s eta 0:00:07\n",
            "     -------------------- ------------------- 6.6/12.8 MB 1.0 MB/s eta 0:00:07\n",
            "     --------------------- ------------------ 6.8/12.8 MB 1.0 MB/s eta 0:00:06\n",
            "     ---------------------- ----------------- 7.1/12.8 MB 1.0 MB/s eta 0:00:06\n",
            "     ----------------------- ---------------- 7.6/12.8 MB 1.1 MB/s eta 0:00:05\n",
            "     ------------------------ --------------- 7.9/12.8 MB 1.1 MB/s eta 0:00:05\n",
            "     -------------------------- ------------- 8.4/12.8 MB 1.1 MB/s eta 0:00:05\n",
            "     --------------------------- ------------ 8.9/12.8 MB 1.1 MB/s eta 0:00:04\n",
            "     ----------------------------- ---------- 9.4/12.8 MB 1.2 MB/s eta 0:00:03\n",
            "     ------------------------------- -------- 10.0/12.8 MB 1.2 MB/s eta 0:00:03\n",
            "     --------------------------------- ------ 10.7/12.8 MB 1.3 MB/s eta 0:00:02\n",
            "     ---------------------------------- ----- 11.0/12.8 MB 1.3 MB/s eta 0:00:02\n",
            "     ----------------------------------- ---- 11.3/12.8 MB 1.3 MB/s eta 0:00:02\n",
            "     ------------------------------------ --- 11.5/12.8 MB 1.3 MB/s eta 0:00:01\n",
            "     ------------------------------------ --- 11.8/12.8 MB 1.3 MB/s eta 0:00:01\n",
            "     ------------------------------------- -- 12.1/12.8 MB 1.3 MB/s eta 0:00:01\n",
            "     -------------------------------------- - 12.3/12.8 MB 1.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------  12.6/12.8 MB 1.3 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 12.8/12.8 MB 1.3 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "57343c2c9a263e96"
      },
      "cell_type": "markdown",
      "source": [
        "## spaCy: Industrial-strength NLP : *https://spacy.io/*"
      ],
      "id": "57343c2c9a263e96"
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T04:31:08.441527Z",
          "start_time": "2024-10-17T04:31:04.479253Z"
        },
        "id": "initial_id"
      },
      "source": [
        "# import spacy"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "b8a84f1cbe85f095",
      "metadata": {
        "id": "b8a84f1cbe85f095"
      },
      "source": [
        "# Load the English language model\n",
        "# Ensure the model is installed\n",
        "# try:\n",
        "#     spacy.cli.download(\"en_core_web_sm\")\n",
        "# except SystemExit:\n",
        "#     pass\n",
        "#\n",
        "# nlp = spacy.load('en_core_web_sm')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:00.363Z",
          "start_time": "2024-10-17T05:15:00.048871Z"
        },
        "id": "b33e4166c6a9b0be"
      },
      "cell_type": "code",
      "source": [
        "import en_core_web_sm\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = en_core_web_sm.load()"
      ],
      "id": "b33e4166c6a9b0be",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "8b9cd965d10bb98b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:07.910528Z",
          "start_time": "2024-10-17T05:15:07.869099Z"
        },
        "id": "8b9cd965d10bb98b"
      },
      "source": [
        "# Sample text for processing\n",
        "\n",
        "text = \"\"\"Building LLM Powered Applications delves into the fundamental concepts, cutting-edge technologies, and practical applications that LLMs offer, ultimately paving the way for the emergence of large foundation models (LFMs) that extend the boundaries of AI capabilities.\n",
        "\n",
        "The book begins with an in-depth introduction to LLMs. We then explore various mainstream architectural frameworks, including both proprietary models (GPT 3.5/4) and open-source models (Falcon LLM), and analyze their unique strengths and differences. Moving ahead, with a focus on the Python-based, lightweight framework called LangChain, we guide you through the process of creating intelligent agents capable of retrieving information from unstructured data and engaging with structured data using LLMs and powerful toolkits. Furthermore, the book ventures into the realm of LFMs, which transcend language modeling to encompass various AI tasks and modalities, such as vision and audio.\n",
        "\n",
        "Whether you are a seasoned AI expert or a newcomer to the field, this book is your roadmap to unlock the full potential of LLMs and forge a new era of intelligent machines.\"\"\"\n",
        "doc = nlp(text)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c67688f01766cc64",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:07.919952Z",
          "start_time": "2024-10-17T05:15:07.916223Z"
        },
        "id": "c67688f01766cc64",
        "outputId": "3585ce5e-63c3-4641-875b-56d25ba5b103"
      },
      "source": [
        "# Part-of-Speech Tagging and Lemmatization\n",
        "\n",
        "print(\"POS Tagging and Lemmatization:\")  # compare stemm - lemma\n",
        "for token in doc:\n",
        "    print(f\"{token.text:<12} | {token.pos_:<10} | {token.lemma_:<10}\")"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POS Tagging and Lemmatization:\n",
            "Building     | VERB       | build     \n",
            "LLM          | PROPN      | LLM       \n",
            "Powered      | PROPN      | Powered   \n",
            "Applications | PROPN      | Applications\n",
            "delves       | NOUN       | delf      \n",
            "into         | ADP        | into      \n",
            "the          | DET        | the       \n",
            "fundamental  | ADJ        | fundamental\n",
            "concepts     | NOUN       | concept   \n",
            ",            | PUNCT      | ,         \n",
            "cutting      | VERB       | cut       \n",
            "-            | PUNCT      | -         \n",
            "edge         | NOUN       | edge      \n",
            "technologies | NOUN       | technology\n",
            ",            | PUNCT      | ,         \n",
            "and          | CCONJ      | and       \n",
            "practical    | ADJ        | practical \n",
            "applications | NOUN       | application\n",
            "that         | PRON       | that      \n",
            "LLMs         | PROPN      | LLMs      \n",
            "offer        | VERB       | offer     \n",
            ",            | PUNCT      | ,         \n",
            "ultimately   | ADV        | ultimately\n",
            "paving       | VERB       | pave      \n",
            "the          | DET        | the       \n",
            "way          | NOUN       | way       \n",
            "for          | ADP        | for       \n",
            "the          | DET        | the       \n",
            "emergence    | NOUN       | emergence \n",
            "of           | ADP        | of        \n",
            "large        | ADJ        | large     \n",
            "foundation   | NOUN       | foundation\n",
            "models       | NOUN       | model     \n",
            "(            | PUNCT      | (         \n",
            "LFMs         | PROPN      | LFMs      \n",
            ")            | PUNCT      | )         \n",
            "that         | PRON       | that      \n",
            "extend       | VERB       | extend    \n",
            "the          | DET        | the       \n",
            "boundaries   | NOUN       | boundary  \n",
            "of           | ADP        | of        \n",
            "AI           | PROPN      | AI        \n",
            "capabilities | NOUN       | capability\n",
            ".            | PUNCT      | .         \n",
            "\n",
            "\n",
            "           | SPACE      | \n",
            "\n",
            "        \n",
            "The          | DET        | the       \n",
            "book         | NOUN       | book      \n",
            "begins       | VERB       | begin     \n",
            "with         | ADP        | with      \n",
            "an           | DET        | an        \n",
            "in           | ADP        | in        \n",
            "-            | PUNCT      | -         \n",
            "depth        | NOUN       | depth     \n",
            "introduction | NOUN       | introduction\n",
            "to           | ADP        | to        \n",
            "LLMs         | PROPN      | LLMs      \n",
            ".            | PUNCT      | .         \n",
            "We           | PRON       | we        \n",
            "then         | ADV        | then      \n",
            "explore      | VERB       | explore   \n",
            "various      | ADJ        | various   \n",
            "mainstream   | ADJ        | mainstream\n",
            "architectural | ADJ        | architectural\n",
            "frameworks   | NOUN       | framework \n",
            ",            | PUNCT      | ,         \n",
            "including    | VERB       | include   \n",
            "both         | DET        | both      \n",
            "proprietary  | ADJ        | proprietary\n",
            "models       | NOUN       | model     \n",
            "(            | PUNCT      | (         \n",
            "GPT          | PROPN      | GPT       \n",
            "3.5/4        | NUM        | 3.5/4     \n",
            ")            | PUNCT      | )         \n",
            "and          | CCONJ      | and       \n",
            "open         | ADJ        | open      \n",
            "-            | PUNCT      | -         \n",
            "source       | NOUN       | source    \n",
            "models       | NOUN       | model     \n",
            "(            | PUNCT      | (         \n",
            "Falcon       | PROPN      | Falcon    \n",
            "LLM          | PROPN      | LLM       \n",
            ")            | PUNCT      | )         \n",
            ",            | PUNCT      | ,         \n",
            "and          | CCONJ      | and       \n",
            "analyze      | VERB       | analyze   \n",
            "their        | PRON       | their     \n",
            "unique       | ADJ        | unique    \n",
            "strengths    | NOUN       | strength  \n",
            "and          | CCONJ      | and       \n",
            "differences  | NOUN       | difference\n",
            ".            | PUNCT      | .         \n",
            "Moving       | VERB       | move      \n",
            "ahead        | ADV        | ahead     \n",
            ",            | PUNCT      | ,         \n",
            "with         | ADP        | with      \n",
            "a            | DET        | a         \n",
            "focus        | NOUN       | focus     \n",
            "on           | ADP        | on        \n",
            "the          | DET        | the       \n",
            "Python       | PROPN      | Python    \n",
            "-            | PUNCT      | -         \n",
            "based        | VERB       | base      \n",
            ",            | PUNCT      | ,         \n",
            "lightweight  | ADJ        | lightweight\n",
            "framework    | NOUN       | framework \n",
            "called       | VERB       | call      \n",
            "LangChain    | PROPN      | LangChain \n",
            ",            | PUNCT      | ,         \n",
            "we           | PRON       | we        \n",
            "guide        | VERB       | guide     \n",
            "you          | PRON       | you       \n",
            "through      | ADP        | through   \n",
            "the          | DET        | the       \n",
            "process      | NOUN       | process   \n",
            "of           | ADP        | of        \n",
            "creating     | VERB       | create    \n",
            "intelligent  | ADJ        | intelligent\n",
            "agents       | NOUN       | agent     \n",
            "capable      | ADJ        | capable   \n",
            "of           | ADP        | of        \n",
            "retrieving   | VERB       | retrieve  \n",
            "information  | NOUN       | information\n",
            "from         | ADP        | from      \n",
            "unstructured | ADJ        | unstructured\n",
            "data         | NOUN       | datum     \n",
            "and          | CCONJ      | and       \n",
            "engaging     | VERB       | engage    \n",
            "with         | ADP        | with      \n",
            "structured   | ADJ        | structured\n",
            "data         | NOUN       | datum     \n",
            "using        | VERB       | use       \n",
            "LLMs         | PROPN      | LLMs      \n",
            "and          | CCONJ      | and       \n",
            "powerful     | ADJ        | powerful  \n",
            "toolkits     | NOUN       | toolkit   \n",
            ".            | PUNCT      | .         \n",
            "Furthermore  | ADV        | furthermore\n",
            ",            | PUNCT      | ,         \n",
            "the          | DET        | the       \n",
            "book         | NOUN       | book      \n",
            "ventures     | VERB       | venture   \n",
            "into         | ADP        | into      \n",
            "the          | DET        | the       \n",
            "realm        | NOUN       | realm     \n",
            "of           | ADP        | of        \n",
            "LFMs         | NOUN       | lfm       \n",
            ",            | PUNCT      | ,         \n",
            "which        | PRON       | which     \n",
            "transcend    | VERB       | transcend \n",
            "language     | NOUN       | language  \n",
            "modeling     | NOUN       | modeling  \n",
            "to           | PART       | to        \n",
            "encompass    | VERB       | encompass \n",
            "various      | ADJ        | various   \n",
            "AI           | PROPN      | AI        \n",
            "tasks        | NOUN       | task      \n",
            "and          | CCONJ      | and       \n",
            "modalities   | NOUN       | modality  \n",
            ",            | PUNCT      | ,         \n",
            "such         | ADJ        | such      \n",
            "as           | ADP        | as        \n",
            "vision       | NOUN       | vision    \n",
            "and          | CCONJ      | and       \n",
            "audio        | NOUN       | audio     \n",
            ".            | PUNCT      | .         \n",
            "\n",
            "\n",
            "           | SPACE      | \n",
            "\n",
            "        \n",
            "Whether      | SCONJ      | whether   \n",
            "you          | PRON       | you       \n",
            "are          | AUX        | be        \n",
            "a            | DET        | a         \n",
            "seasoned     | ADJ        | seasoned  \n",
            "AI           | PROPN      | AI        \n",
            "expert       | NOUN       | expert    \n",
            "or           | CCONJ      | or        \n",
            "a            | DET        | a         \n",
            "newcomer     | NOUN       | newcomer  \n",
            "to           | ADP        | to        \n",
            "the          | DET        | the       \n",
            "field        | NOUN       | field     \n",
            ",            | PUNCT      | ,         \n",
            "this         | DET        | this      \n",
            "book         | NOUN       | book      \n",
            "is           | AUX        | be        \n",
            "your         | PRON       | your      \n",
            "roadmap      | NOUN       | roadmap   \n",
            "to           | PART       | to        \n",
            "unlock       | VERB       | unlock    \n",
            "the          | DET        | the       \n",
            "full         | ADJ        | full      \n",
            "potential    | NOUN       | potential \n",
            "of           | ADP        | of        \n",
            "LLMs         | PROPN      | LLMs      \n",
            "and          | CCONJ      | and       \n",
            "forge        | VERB       | forge     \n",
            "a            | DET        | a         \n",
            "new          | ADJ        | new       \n",
            "era          | NOUN       | era       \n",
            "of           | ADP        | of        \n",
            "intelligent  | ADJ        | intelligent\n",
            "machines     | NOUN       | machine   \n",
            ".            | PUNCT      | .         \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c9f64ff9bb97954c"
      },
      "cell_type": "markdown",
      "source": [
        "## Named Entity Recognition\n"
      ],
      "id": "c9f64ff9bb97954c"
    },
    {
      "cell_type": "code",
      "id": "ec5ce781c6f8438d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:07.950784Z",
          "start_time": "2024-10-17T05:15:07.946609Z"
        },
        "id": "ec5ce781c6f8438d",
        "outputId": "e713344e-3f8b-49f4-8d19-406a7351c80f"
      },
      "source": [
        "print(\"\\nNamed Entity Recognition:\")\n",
        "\n",
        "for entity in doc.ents:\n",
        "    print(f\"{entity.text:<35} | {entity.label_:<15} | {spacy.explain(entity.label_)}\")"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Named Entity Recognition:\n",
            "Building LLM Powered Applications   | ORG             | Companies, agencies, institutions, etc.\n",
            "AI                                  | GPE             | Countries, cities, states\n",
            "GPT                                 | ORG             | Companies, agencies, institutions, etc.\n",
            "3.5/4                               | CARDINAL        | Numerals that do not fall under another type\n",
            "Falcon LLM                          | ORG             | Companies, agencies, institutions, etc.\n",
            "Python                              | ORG             | Companies, agencies, institutions, etc.\n",
            "LangChain                           | ORG             | Companies, agencies, institutions, etc.\n",
            "AI                                  | GPE             | Countries, cities, states\n",
            "AI                                  | ORG             | Companies, agencies, institutions, etc.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "1368f04ca0e97834",
      "metadata": {
        "id": "1368f04ca0e97834"
      },
      "source": [
        "### Spacy does not have built-in stemming functionality like NLTK, but we can implement a simple stemming function using the **PorterStemmer** from NLTK"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:07.996439Z",
          "start_time": "2024-10-17T05:15:07.967075Z"
        },
        "id": "94cd405e9e523701",
        "outputId": "4ff9cf11-8a21-4ea4-d8f9-6420a4611f46"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')"
      ],
      "id": "94cd405e9e523701",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Onepoint\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "48aaf67e5600b8f0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:08.006387Z",
          "start_time": "2024-10-17T05:15:08.003057Z"
        },
        "id": "48aaf67e5600b8f0"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "79d01860a179689d"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenize using NLTK for stemming"
      ],
      "id": "79d01860a179689d"
    },
    {
      "cell_type": "code",
      "id": "a0cfc5e6eebecd23",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:08.024537Z",
          "start_time": "2024-10-17T05:15:08.017761Z"
        },
        "id": "a0cfc5e6eebecd23"
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "nltk_tokens = word_tokenize(text)\n",
        "\n",
        "# Stemming using NLTK\n",
        "stemmed_words = [stemmer.stem(token) for token in nltk_tokens]  # applying the PorterStemmer to each token"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "9380ef2208a49f72",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:08.035044Z",
          "start_time": "2024-10-17T05:15:08.030808Z"
        },
        "id": "9380ef2208a49f72",
        "outputId": "ca34dcda-db0d-4fa6-a27b-26c97050f204"
      },
      "source": [
        "print(stemmed_words)"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['build', 'llm', 'power', 'applic', 'delv', 'into', 'the', 'fundament', 'concept', ',', 'cutting-edg', 'technolog', ',', 'and', 'practic', 'applic', 'that', 'llm', 'offer', ',', 'ultim', 'pave', 'the', 'way', 'for', 'the', 'emerg', 'of', 'larg', 'foundat', 'model', '(', 'lfm', ')', 'that', 'extend', 'the', 'boundari', 'of', 'ai', 'capabl', '.', 'the', 'book', 'begin', 'with', 'an', 'in-depth', 'introduct', 'to', 'llm', '.', 'we', 'then', 'explor', 'variou', 'mainstream', 'architectur', 'framework', ',', 'includ', 'both', 'proprietari', 'model', '(', 'gpt', '3.5/4', ')', 'and', 'open-sourc', 'model', '(', 'falcon', 'llm', ')', ',', 'and', 'analyz', 'their', 'uniqu', 'strength', 'and', 'differ', '.', 'move', 'ahead', ',', 'with', 'a', 'focu', 'on', 'the', 'python-bas', ',', 'lightweight', 'framework', 'call', 'langchain', ',', 'we', 'guid', 'you', 'through', 'the', 'process', 'of', 'creat', 'intellig', 'agent', 'capabl', 'of', 'retriev', 'inform', 'from', 'unstructur', 'data', 'and', 'engag', 'with', 'structur', 'data', 'use', 'llm', 'and', 'power', 'toolkit', '.', 'furthermor', ',', 'the', 'book', 'ventur', 'into', 'the', 'realm', 'of', 'lfm', ',', 'which', 'transcend', 'languag', 'model', 'to', 'encompass', 'variou', 'ai', 'task', 'and', 'modal', ',', 'such', 'as', 'vision', 'and', 'audio', '.', 'whether', 'you', 'are', 'a', 'season', 'ai', 'expert', 'or', 'a', 'newcom', 'to', 'the', 'field', ',', 'thi', 'book', 'is', 'your', 'roadmap', 'to', 'unlock', 'the', 'full', 'potenti', 'of', 'llm', 'and', 'forg', 'a', 'new', 'era', 'of', 'intellig', 'machin', '.']\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ef76ac6a3b4bea5"
      },
      "cell_type": "markdown",
      "source": [
        "## Each word from **nltk_tokens** is paired with its <u>**stemmed**</u> equivalent in **stemmed_words** and printed in a neatly formatted table."
      ],
      "id": "ef76ac6a3b4bea5"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:08.054978Z",
          "start_time": "2024-10-17T05:15:08.050375Z"
        },
        "id": "bd44c674d504a5a6",
        "outputId": "747893a4-f398-4242-c944-0dda1cba41f2"
      },
      "cell_type": "code",
      "source": [
        "print('NLTK Tokens:    | Stemmed Words:')\n",
        "\n",
        "for original, stemmed in zip(nltk_tokens, stemmed_words):\n",
        "    print(f\"{original:15} | {stemmed:<20}\")  #Part-of-Speech Tagging and Lemmatization"
      ],
      "id": "bd44c674d504a5a6",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Tokens:    | Stemmed Words:\n",
            "Building        | build               \n",
            "LLM             | llm                 \n",
            "Powered         | power               \n",
            "Applications    | applic              \n",
            "delves          | delv                \n",
            "into            | into                \n",
            "the             | the                 \n",
            "fundamental     | fundament           \n",
            "concepts        | concept             \n",
            ",               | ,                   \n",
            "cutting-edge    | cutting-edg         \n",
            "technologies    | technolog           \n",
            ",               | ,                   \n",
            "and             | and                 \n",
            "practical       | practic             \n",
            "applications    | applic              \n",
            "that            | that                \n",
            "LLMs            | llm                 \n",
            "offer           | offer               \n",
            ",               | ,                   \n",
            "ultimately      | ultim               \n",
            "paving          | pave                \n",
            "the             | the                 \n",
            "way             | way                 \n",
            "for             | for                 \n",
            "the             | the                 \n",
            "emergence       | emerg               \n",
            "of              | of                  \n",
            "large           | larg                \n",
            "foundation      | foundat             \n",
            "models          | model               \n",
            "(               | (                   \n",
            "LFMs            | lfm                 \n",
            ")               | )                   \n",
            "that            | that                \n",
            "extend          | extend              \n",
            "the             | the                 \n",
            "boundaries      | boundari            \n",
            "of              | of                  \n",
            "AI              | ai                  \n",
            "capabilities    | capabl              \n",
            ".               | .                   \n",
            "The             | the                 \n",
            "book            | book                \n",
            "begins          | begin               \n",
            "with            | with                \n",
            "an              | an                  \n",
            "in-depth        | in-depth            \n",
            "introduction    | introduct           \n",
            "to              | to                  \n",
            "LLMs            | llm                 \n",
            ".               | .                   \n",
            "We              | we                  \n",
            "then            | then                \n",
            "explore         | explor              \n",
            "various         | variou              \n",
            "mainstream      | mainstream          \n",
            "architectural   | architectur         \n",
            "frameworks      | framework           \n",
            ",               | ,                   \n",
            "including       | includ              \n",
            "both            | both                \n",
            "proprietary     | proprietari         \n",
            "models          | model               \n",
            "(               | (                   \n",
            "GPT             | gpt                 \n",
            "3.5/4           | 3.5/4               \n",
            ")               | )                   \n",
            "and             | and                 \n",
            "open-source     | open-sourc          \n",
            "models          | model               \n",
            "(               | (                   \n",
            "Falcon          | falcon              \n",
            "LLM             | llm                 \n",
            ")               | )                   \n",
            ",               | ,                   \n",
            "and             | and                 \n",
            "analyze         | analyz              \n",
            "their           | their               \n",
            "unique          | uniqu               \n",
            "strengths       | strength            \n",
            "and             | and                 \n",
            "differences     | differ              \n",
            ".               | .                   \n",
            "Moving          | move                \n",
            "ahead           | ahead               \n",
            ",               | ,                   \n",
            "with            | with                \n",
            "a               | a                   \n",
            "focus           | focu                \n",
            "on              | on                  \n",
            "the             | the                 \n",
            "Python-based    | python-bas          \n",
            ",               | ,                   \n",
            "lightweight     | lightweight         \n",
            "framework       | framework           \n",
            "called          | call                \n",
            "LangChain       | langchain           \n",
            ",               | ,                   \n",
            "we              | we                  \n",
            "guide           | guid                \n",
            "you             | you                 \n",
            "through         | through             \n",
            "the             | the                 \n",
            "process         | process             \n",
            "of              | of                  \n",
            "creating        | creat               \n",
            "intelligent     | intellig            \n",
            "agents          | agent               \n",
            "capable         | capabl              \n",
            "of              | of                  \n",
            "retrieving      | retriev             \n",
            "information     | inform              \n",
            "from            | from                \n",
            "unstructured    | unstructur          \n",
            "data            | data                \n",
            "and             | and                 \n",
            "engaging        | engag               \n",
            "with            | with                \n",
            "structured      | structur            \n",
            "data            | data                \n",
            "using           | use                 \n",
            "LLMs            | llm                 \n",
            "and             | and                 \n",
            "powerful        | power               \n",
            "toolkits        | toolkit             \n",
            ".               | .                   \n",
            "Furthermore     | furthermor          \n",
            ",               | ,                   \n",
            "the             | the                 \n",
            "book            | book                \n",
            "ventures        | ventur              \n",
            "into            | into                \n",
            "the             | the                 \n",
            "realm           | realm               \n",
            "of              | of                  \n",
            "LFMs            | lfm                 \n",
            ",               | ,                   \n",
            "which           | which               \n",
            "transcend       | transcend           \n",
            "language        | languag             \n",
            "modeling        | model               \n",
            "to              | to                  \n",
            "encompass       | encompass           \n",
            "various         | variou              \n",
            "AI              | ai                  \n",
            "tasks           | task                \n",
            "and             | and                 \n",
            "modalities      | modal               \n",
            ",               | ,                   \n",
            "such            | such                \n",
            "as              | as                  \n",
            "vision          | vision              \n",
            "and             | and                 \n",
            "audio           | audio               \n",
            ".               | .                   \n",
            "Whether         | whether             \n",
            "you             | you                 \n",
            "are             | are                 \n",
            "a               | a                   \n",
            "seasoned        | season              \n",
            "AI              | ai                  \n",
            "expert          | expert              \n",
            "or              | or                  \n",
            "a               | a                   \n",
            "newcomer        | newcom              \n",
            "to              | to                  \n",
            "the             | the                 \n",
            "field           | field               \n",
            ",               | ,                   \n",
            "this            | thi                 \n",
            "book            | book                \n",
            "is              | is                  \n",
            "your            | your                \n",
            "roadmap         | roadmap             \n",
            "to              | to                  \n",
            "unlock          | unlock              \n",
            "the             | the                 \n",
            "full            | full                \n",
            "potential       | potenti             \n",
            "of              | of                  \n",
            "LLMs            | llm                 \n",
            "and             | and                 \n",
            "forge           | forg                \n",
            "a               | a                   \n",
            "new             | new                 \n",
            "era             | era                 \n",
            "of              | of                  \n",
            "intelligent     | intellig            \n",
            "machines        | machin              \n",
            ".               | .                   \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-17T05:15:08.075780Z",
          "start_time": "2024-10-17T05:15:08.070794Z"
        },
        "id": "45a7adc56309c0b5",
        "outputId": "d70cefc8-b50a-4afc-9bcd-cc93695faf39"
      },
      "cell_type": "code",
      "source": [
        "print('Tokens >  Stemmed  > Lemma  >  POS')\n",
        "\n",
        "for token, stemmed in zip(doc, stemmed_words):\n",
        "    print(f\"t: {token.text:<13} |s: {stemmed:<12} |l: {token.lemma_:<15} | {token.pos_:<10}\")"
      ],
      "id": "45a7adc56309c0b5",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens >  Stemmed  > Lemma  >  POS\n",
            "t: Building      |s: build        |l: build           | VERB      \n",
            "t: LLM           |s: llm          |l: LLM             | PROPN     \n",
            "t: Powered       |s: power        |l: Powered         | PROPN     \n",
            "t: Applications  |s: applic       |l: Applications    | PROPN     \n",
            "t: delves        |s: delv         |l: delf            | NOUN      \n",
            "t: into          |s: into         |l: into            | ADP       \n",
            "t: the           |s: the          |l: the             | DET       \n",
            "t: fundamental   |s: fundament    |l: fundamental     | ADJ       \n",
            "t: concepts      |s: concept      |l: concept         | NOUN      \n",
            "t: ,             |s: ,            |l: ,               | PUNCT     \n",
            "t: cutting       |s: cutting-edg  |l: cut             | VERB      \n",
            "t: -             |s: technolog    |l: -               | PUNCT     \n",
            "t: edge          |s: ,            |l: edge            | NOUN      \n",
            "t: technologies  |s: and          |l: technology      | NOUN      \n",
            "t: ,             |s: practic      |l: ,               | PUNCT     \n",
            "t: and           |s: applic       |l: and             | CCONJ     \n",
            "t: practical     |s: that         |l: practical       | ADJ       \n",
            "t: applications  |s: llm          |l: application     | NOUN      \n",
            "t: that          |s: offer        |l: that            | PRON      \n",
            "t: LLMs          |s: ,            |l: LLMs            | PROPN     \n",
            "t: offer         |s: ultim        |l: offer           | VERB      \n",
            "t: ,             |s: pave         |l: ,               | PUNCT     \n",
            "t: ultimately    |s: the          |l: ultimately      | ADV       \n",
            "t: paving        |s: way          |l: pave            | VERB      \n",
            "t: the           |s: for          |l: the             | DET       \n",
            "t: way           |s: the          |l: way             | NOUN      \n",
            "t: for           |s: emerg        |l: for             | ADP       \n",
            "t: the           |s: of           |l: the             | DET       \n",
            "t: emergence     |s: larg         |l: emergence       | NOUN      \n",
            "t: of            |s: foundat      |l: of              | ADP       \n",
            "t: large         |s: model        |l: large           | ADJ       \n",
            "t: foundation    |s: (            |l: foundation      | NOUN      \n",
            "t: models        |s: lfm          |l: model           | NOUN      \n",
            "t: (             |s: )            |l: (               | PUNCT     \n",
            "t: LFMs          |s: that         |l: LFMs            | PROPN     \n",
            "t: )             |s: extend       |l: )               | PUNCT     \n",
            "t: that          |s: the          |l: that            | PRON      \n",
            "t: extend        |s: boundari     |l: extend          | VERB      \n",
            "t: the           |s: of           |l: the             | DET       \n",
            "t: boundaries    |s: ai           |l: boundary        | NOUN      \n",
            "t: of            |s: capabl       |l: of              | ADP       \n",
            "t: AI            |s: .            |l: AI              | PROPN     \n",
            "t: capabilities  |s: the          |l: capability      | NOUN      \n",
            "t: .             |s: book         |l: .               | PUNCT     \n",
            "t: \n",
            "\n",
            "            |s: begin        |l: \n",
            "\n",
            "              | SPACE     \n",
            "t: The           |s: with         |l: the             | DET       \n",
            "t: book          |s: an           |l: book            | NOUN      \n",
            "t: begins        |s: in-depth     |l: begin           | VERB      \n",
            "t: with          |s: introduct    |l: with            | ADP       \n",
            "t: an            |s: to           |l: an              | DET       \n",
            "t: in            |s: llm          |l: in              | ADP       \n",
            "t: -             |s: .            |l: -               | PUNCT     \n",
            "t: depth         |s: we           |l: depth           | NOUN      \n",
            "t: introduction  |s: then         |l: introduction    | NOUN      \n",
            "t: to            |s: explor       |l: to              | ADP       \n",
            "t: LLMs          |s: variou       |l: LLMs            | PROPN     \n",
            "t: .             |s: mainstream   |l: .               | PUNCT     \n",
            "t: We            |s: architectur  |l: we              | PRON      \n",
            "t: then          |s: framework    |l: then            | ADV       \n",
            "t: explore       |s: ,            |l: explore         | VERB      \n",
            "t: various       |s: includ       |l: various         | ADJ       \n",
            "t: mainstream    |s: both         |l: mainstream      | ADJ       \n",
            "t: architectural |s: proprietari  |l: architectural   | ADJ       \n",
            "t: frameworks    |s: model        |l: framework       | NOUN      \n",
            "t: ,             |s: (            |l: ,               | PUNCT     \n",
            "t: including     |s: gpt          |l: include         | VERB      \n",
            "t: both          |s: 3.5/4        |l: both            | DET       \n",
            "t: proprietary   |s: )            |l: proprietary     | ADJ       \n",
            "t: models        |s: and          |l: model           | NOUN      \n",
            "t: (             |s: open-sourc   |l: (               | PUNCT     \n",
            "t: GPT           |s: model        |l: GPT             | PROPN     \n",
            "t: 3.5/4         |s: (            |l: 3.5/4           | NUM       \n",
            "t: )             |s: falcon       |l: )               | PUNCT     \n",
            "t: and           |s: llm          |l: and             | CCONJ     \n",
            "t: open          |s: )            |l: open            | ADJ       \n",
            "t: -             |s: ,            |l: -               | PUNCT     \n",
            "t: source        |s: and          |l: source          | NOUN      \n",
            "t: models        |s: analyz       |l: model           | NOUN      \n",
            "t: (             |s: their        |l: (               | PUNCT     \n",
            "t: Falcon        |s: uniqu        |l: Falcon          | PROPN     \n",
            "t: LLM           |s: strength     |l: LLM             | PROPN     \n",
            "t: )             |s: and          |l: )               | PUNCT     \n",
            "t: ,             |s: differ       |l: ,               | PUNCT     \n",
            "t: and           |s: .            |l: and             | CCONJ     \n",
            "t: analyze       |s: move         |l: analyze         | VERB      \n",
            "t: their         |s: ahead        |l: their           | PRON      \n",
            "t: unique        |s: ,            |l: unique          | ADJ       \n",
            "t: strengths     |s: with         |l: strength        | NOUN      \n",
            "t: and           |s: a            |l: and             | CCONJ     \n",
            "t: differences   |s: focu         |l: difference      | NOUN      \n",
            "t: .             |s: on           |l: .               | PUNCT     \n",
            "t: Moving        |s: the          |l: move            | VERB      \n",
            "t: ahead         |s: python-bas   |l: ahead           | ADV       \n",
            "t: ,             |s: ,            |l: ,               | PUNCT     \n",
            "t: with          |s: lightweight  |l: with            | ADP       \n",
            "t: a             |s: framework    |l: a               | DET       \n",
            "t: focus         |s: call         |l: focus           | NOUN      \n",
            "t: on            |s: langchain    |l: on              | ADP       \n",
            "t: the           |s: ,            |l: the             | DET       \n",
            "t: Python        |s: we           |l: Python          | PROPN     \n",
            "t: -             |s: guid         |l: -               | PUNCT     \n",
            "t: based         |s: you          |l: base            | VERB      \n",
            "t: ,             |s: through      |l: ,               | PUNCT     \n",
            "t: lightweight   |s: the          |l: lightweight     | ADJ       \n",
            "t: framework     |s: process      |l: framework       | NOUN      \n",
            "t: called        |s: of           |l: call            | VERB      \n",
            "t: LangChain     |s: creat        |l: LangChain       | PROPN     \n",
            "t: ,             |s: intellig     |l: ,               | PUNCT     \n",
            "t: we            |s: agent        |l: we              | PRON      \n",
            "t: guide         |s: capabl       |l: guide           | VERB      \n",
            "t: you           |s: of           |l: you             | PRON      \n",
            "t: through       |s: retriev      |l: through         | ADP       \n",
            "t: the           |s: inform       |l: the             | DET       \n",
            "t: process       |s: from         |l: process         | NOUN      \n",
            "t: of            |s: unstructur   |l: of              | ADP       \n",
            "t: creating      |s: data         |l: create          | VERB      \n",
            "t: intelligent   |s: and          |l: intelligent     | ADJ       \n",
            "t: agents        |s: engag        |l: agent           | NOUN      \n",
            "t: capable       |s: with         |l: capable         | ADJ       \n",
            "t: of            |s: structur     |l: of              | ADP       \n",
            "t: retrieving    |s: data         |l: retrieve        | VERB      \n",
            "t: information   |s: use          |l: information     | NOUN      \n",
            "t: from          |s: llm          |l: from            | ADP       \n",
            "t: unstructured  |s: and          |l: unstructured    | ADJ       \n",
            "t: data          |s: power        |l: datum           | NOUN      \n",
            "t: and           |s: toolkit      |l: and             | CCONJ     \n",
            "t: engaging      |s: .            |l: engage          | VERB      \n",
            "t: with          |s: furthermor   |l: with            | ADP       \n",
            "t: structured    |s: ,            |l: structured      | ADJ       \n",
            "t: data          |s: the          |l: datum           | NOUN      \n",
            "t: using         |s: book         |l: use             | VERB      \n",
            "t: LLMs          |s: ventur       |l: LLMs            | PROPN     \n",
            "t: and           |s: into         |l: and             | CCONJ     \n",
            "t: powerful      |s: the          |l: powerful        | ADJ       \n",
            "t: toolkits      |s: realm        |l: toolkit         | NOUN      \n",
            "t: .             |s: of           |l: .               | PUNCT     \n",
            "t: Furthermore   |s: lfm          |l: furthermore     | ADV       \n",
            "t: ,             |s: ,            |l: ,               | PUNCT     \n",
            "t: the           |s: which        |l: the             | DET       \n",
            "t: book          |s: transcend    |l: book            | NOUN      \n",
            "t: ventures      |s: languag      |l: venture         | VERB      \n",
            "t: into          |s: model        |l: into            | ADP       \n",
            "t: the           |s: to           |l: the             | DET       \n",
            "t: realm         |s: encompass    |l: realm           | NOUN      \n",
            "t: of            |s: variou       |l: of              | ADP       \n",
            "t: LFMs          |s: ai           |l: lfm             | NOUN      \n",
            "t: ,             |s: task         |l: ,               | PUNCT     \n",
            "t: which         |s: and          |l: which           | PRON      \n",
            "t: transcend     |s: modal        |l: transcend       | VERB      \n",
            "t: language      |s: ,            |l: language        | NOUN      \n",
            "t: modeling      |s: such         |l: modeling        | NOUN      \n",
            "t: to            |s: as           |l: to              | PART      \n",
            "t: encompass     |s: vision       |l: encompass       | VERB      \n",
            "t: various       |s: and          |l: various         | ADJ       \n",
            "t: AI            |s: audio        |l: AI              | PROPN     \n",
            "t: tasks         |s: .            |l: task            | NOUN      \n",
            "t: and           |s: whether      |l: and             | CCONJ     \n",
            "t: modalities    |s: you          |l: modality        | NOUN      \n",
            "t: ,             |s: are          |l: ,               | PUNCT     \n",
            "t: such          |s: a            |l: such            | ADJ       \n",
            "t: as            |s: season       |l: as              | ADP       \n",
            "t: vision        |s: ai           |l: vision          | NOUN      \n",
            "t: and           |s: expert       |l: and             | CCONJ     \n",
            "t: audio         |s: or           |l: audio           | NOUN      \n",
            "t: .             |s: a            |l: .               | PUNCT     \n",
            "t: \n",
            "\n",
            "            |s: newcom       |l: \n",
            "\n",
            "              | SPACE     \n",
            "t: Whether       |s: to           |l: whether         | SCONJ     \n",
            "t: you           |s: the          |l: you             | PRON      \n",
            "t: are           |s: field        |l: be              | AUX       \n",
            "t: a             |s: ,            |l: a               | DET       \n",
            "t: seasoned      |s: thi          |l: seasoned        | ADJ       \n",
            "t: AI            |s: book         |l: AI              | PROPN     \n",
            "t: expert        |s: is           |l: expert          | NOUN      \n",
            "t: or            |s: your         |l: or              | CCONJ     \n",
            "t: a             |s: roadmap      |l: a               | DET       \n",
            "t: newcomer      |s: to           |l: newcomer        | NOUN      \n",
            "t: to            |s: unlock       |l: to              | ADP       \n",
            "t: the           |s: the          |l: the             | DET       \n",
            "t: field         |s: full         |l: field           | NOUN      \n",
            "t: ,             |s: potenti      |l: ,               | PUNCT     \n",
            "t: this          |s: of           |l: this            | DET       \n",
            "t: book          |s: llm          |l: book            | NOUN      \n",
            "t: is            |s: and          |l: be              | AUX       \n",
            "t: your          |s: forg         |l: your            | PRON      \n",
            "t: roadmap       |s: a            |l: roadmap         | NOUN      \n",
            "t: to            |s: new          |l: to              | PART      \n",
            "t: unlock        |s: era          |l: unlock          | VERB      \n",
            "t: the           |s: of           |l: the             | DET       \n",
            "t: full          |s: intellig     |l: full            | ADJ       \n",
            "t: potential     |s: machin       |l: potential       | NOUN      \n",
            "t: of            |s: .            |l: of              | ADP       \n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}